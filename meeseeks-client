#!/usr/bin/env python3

import sys
import logging
import json
import time

from meeseeks import Client
from meeseeks.util import cmdline_parser, read_cfg_files

def usage():
    print("""
%s [options] <command> [args...]

    commands are:
        submit <pool[@node]> <executable> [args....]
            options for submit:
                nodelist= (list of nodes to route job through)
                stdin= stdout= stderr= (redirect job in/out/err to files named)
                restart= (1=restart when done)
                retries= (times to retry if job fails)
                runtime= (max runtime of job)
                id= (job id to submit changes to existing job)
                state= (change existing job state, 'new' will restart finished job)
                hold= (1=queue but do not start job)

        get [jobids | filter] (get all or specified job info as JSON)
            jobids are any number of job id arguments
            filter is any job attributes such as node= pool= state=

        ls [filter] (list job ids)

        set <jobids | filter :> key=value ... (set key=value in jobs matching jobids or filter)
            if a filter is provided, : is used to delimit filter key=value from set key=value

        kill <jobids | filter> (kill job)

        reset <jobids | filter> (restart job)

        show [filter] {nodes pools jobs active tree} 
            (prints a foat or tree of cluster status, 
             specify which elements to show, defaults to flat/all)

        nodes (prints full node status JSON)

        pools (prints full pool status JSON)

        config [key=value] [node]
            get/sends config to directly connected or specified node

    generic options are: 
        address= (default localhost)
        port= (defult 13700)
        refresh= (interval to continuously refresh status until no jobs left)

"""%sys.argv[0])

def pretty_print(d): print (json.dumps(d, sort_keys=True, indent=4))

def show(client,args,**kwargs):     
    status=client.status() 
    nodes=status.get('nodes',{})
    pools=status.get('pools',{})
    kwpool=kwargs.get('pool')
    if kwpool: del kwargs['pool']
    kwnode=kwargs.get('node')
    if kwnode: del kwargs['node']
    if 'nodes' not in args and 'pools' not in args and 'jobs' not in args:
        args.extend(['nodes','pools','jobs'])
    #put pool and job status on nodes
    for n,node in nodes.items():
        if kwnode and n != kwnode: continue
        for p,pnodes in pools.items():
            if kwpool and p != kwpool: continue
            if n in pnodes: node.setdefault('free',{})[p]=pnodes[n]
        jobs=client.query(node=n,**kwargs)
        for jid,job in jobs.items(): node.setdefault('jobs',{}).setdefault(job['pool'],{})[jid]=job
    #now we put nodes under other nodes
    def _tree(s):
        for n in list(s.keys()):
            if n in s: #already moved?
                node=s[n]
                if not node.get('online'): continue
                for dn in node.get('routing',[]):
                    if dn in s and dn != n: #we can move this node
                        s[n].setdefault('next',{})[dn]=s[dn]
                        del s[dn]
                if s[n].get('next'): _tree(s[n]['next']) #walk downstream
    if 'tree' in args: _tree(nodes)
    #now we print the tree
    def _print(s,i=0):
        for n,node in sorted(s.items()):
            if 'nodes' in args:
                l='\t'*i + n+'\t'
                if node.get('online'): l+='online'
                else: l+='offline'
                l+='\t%s'%node.get('loadavg')
                if n: print(l)
            pn=set(node.get('free',{}).keys())|set(node.get('jobs',{}).keys())
            for p in sorted(pn):
                if 'nodes' in args: l='\t'*i + '\t'
                else: l=''
                l+='pool %s@%s'%(p,n)
                jobs=node.get('jobs',{}).get(p,{})
                jc=len(jobs)
                l+='\t%s jobs'%jc
                free=node.get('free',{}).get(p)
                if type(free) is int: l+='\t%s slots free'%free
                if 'pools' in args and ('active' not in args or jc): print (l)
                l=''
                if 'nodes' in args: l+='\t'*i+'\t'
                if 'pools' in args: l+='\t'
                if 'jobs' in args:
                    for (jid,job) in sorted(jobs.items(),key=lambda j: (j[1].get('state')) ):
                        print(l+'%s\t%s (%s/%s)\t%s'%(
                            jid,
                            job['state'],job['start_count'],job['fail_count'],
                            ' '.join(job.get('args',[]))) )
            if 'next' in node:
                _print(node['next'],i+1)
    _print(nodes,0)

# cmd=first non cfg argument
# args=remaining arguments
cfg={ 'address':'localhost' } 
try:
    cfg,args=cmdline_parser(sys.argv[1:])
    cmd,args=args[0],args[1:] #end of options
    if 'file' in cfg: cfg.update(read_cfg_files(cfg['file']))
    logging.basicConfig(level=cfg.get('log',logging.INFO))
    logging.debug('%s %s %s'%(cfg,cmd,args))
    client=Client(**cfg) #create client and connect
    jids,query=None,{}
    #if we will be refreshing, refresh now until state populated
    if cfg.get('refresh'):
        while not client.get_node_status(): time.sleep(1)

    if cmd == 'submit':
        #get pool, args and optional node selection
        pool=jobargs=node=None
        if args: 
            pool=args[0]
            if len(args)>1: jobargs=args[1:]
        if pool and '@' in pool: pool,node=pool.split('@',1)
        #if we are refreshing on the job, submit locally and let it dispatch
        if cfg.get('refresh'): jids=[client.submit_job(pool=pool,args=jobargs,node=node,**cfg)]
        #submit directly and return jid
        else: print(client.submit(pool=pool,args=jobargs,node=node,**cfg))

    else: #if not submit, parse as key=value args and job ids
        kwargs,args=cmdline_parser(args)
        if cmd == 'get': #get jobs by ids or filter on key=value
            if cfg.get('refresh'):
                if args: jids=args
                else: jids=True #get all
            elif args: pretty_print(client.query(ids=args))
            else: pretty_print(client.query(**kwargs))

        elif cmd == 'set': #set k=v in matching jobs
            #kwargs will be set if we have initial k=v args like 'pool=... : key=...' 
            if kwargs: jids=client.ls(**kwargs) #we were provided a filter
            else: jids=[arg for arg in args if '=' not in arg] #no filter, we have 'jobid jobid key=...'
            kwargs,args=cmdline_parser([arg for arg in args if '=' in arg]) #parse following k=v args
            for jid in jids: client.submit(id=jid,**kwargs) #submit changes 
            if jids: pretty_print(client.query(ids=jids)) #print changes 

        elif cmd == 'ls': pretty_print(client.ls(**kwargs))

        elif cmd == 'kill': pretty_print(client.kill(args,**kwargs))

        elif cmd == 'reset': #reset jobs
            #to reset active jobs we have to kill them and wait for active=False
            jids=list(jid for (jid,job) in client.kill(args,**kwargs).items() if job)
            while jids: #while we have remaining jobs
                #restart jobs that are now inactive
                for jid in list(jid for (jid,job) in client.query(ids=jids).items() if not job.get('active')):
                    client.submit(id=jid,state='new') #submit to existing and change state to new, this resets job
                    pretty_print(client.query(jid))
                    jids.remove(jid) #remove from list
                if jids:
                    time.sleep(cfg.get('refresh',1)) #if some jobs are still active, wait and try again

        elif cmd == 'nodes': 
            if cfg.get('refresh'): 
                while True:
                    pretty_print(client.get_node_status())
                    time.sleep(cfg.get('refresh'))
            else: pretty_print(client.status()['nodes'])

        elif cmd == 'pools': 
            if cfg.get('refresh'): 
                while True:
                    pretty_print(client.get_pool_status())
                    time.sleep(cfg.get('refresh'))
            else: pretty_print(client.status()['pools'])

        elif cmd == 'config': 
            if 'file' in kwargs: kwargs.update(read_cfg_files(kwargs['file']))
            if args:
                for node in args: 
                    print(client.submit(pool='__config',node=node,args=kwargs))
            else: pretty_print(client.request(dict(config=kwargs))) #peer config push

        elif cmd == 'show': show(client,args,**kwargs) #pretty print full cluster

        else: sys.exit(usage())
    
    #refreshing on jobs
    if jids and cfg.get('refresh'):
        seq={} #sequence numbers for printing updates
        while True: 
            if jids is True: jobs=client.get(**kwargs)
            else: jobs=dict((jid,client.get_job(jid)) for jid in jids)
            if not any(jobs.values()): break #exit when no jobs left
            #print updates (when job seq != saved seq)
            updates=dict((jid,job) for (jid,job) in jobs.items() if job['seq'] != seq.get(jid))
            if updates: pretty_print(updates)
            seq=dict((jid,job['seq']) for (jid,job) in jobs.items())
            time.sleep(cfg.get('refresh'))
except Exception as e: print (e,file=sys.stderr)

#if we were polling state, stop gracefully
if cfg.get('refresh'): client.close()