#!/usr/bin/env python3

import sys
import logging
import json
import time

from meeseeks import Client
from meeseeks.util import cmdline_parser, read_cfg_files

def usage():
    print("""
%s [options] <command> [args...]

    commands are:
        submit <pool[@node]> <executable> [args....]
            options for submit:
                nodelist= (list of nodes to route job through)
                stdin= stdout= stderr= (redirect job in/out/err to files named)
                restart= (1=restart when done)
                retries= (times to retry if job fails)
                runtime= (max runtime of job)
                id= (job id to submit changes to existing job)
                state= (change existing job state, 'new' will restart finished job)
                hold= (1=queue but do not start job)

        get [jobid,jobid... | filter] (get all or specified job info as JSON)
        ls [filter] (list job ids)
            filter for get/ls:
                node= pool= state= (query filters for jobs)

        kill <jobid> [,jobid...]

        show [filter] {nodes pools jobs active} 
            (prints a cluster status tree, specify which elements to show, defaults to all)

        nodes (prints full node status JSON)

        pools (prints full pool status JSON)

        config [key=value] [node]
            get/sends config to directly connected or specified node

    generic options are: 
        address= (default localhost)
        port= (defult 13700)
        refresh= (interval to continuously refresh status until no jobs left)

"""%sys.argv[0])

def pretty_print(d): print (json.dumps(d, sort_keys=True, indent=4))

def show(args,**kwargs):      
    nodes=client.status().get('nodes',{})
    pools=client.status().get('pools',{})
    if 'nodes' not in args and 'pools' not in args and 'jobs' not in args:
        args.extend(['nodes','pools','jobs'])
    #put pool and job status on nodes
    for n,node in nodes.items():
        for p,pnodes in pools.items():
            if n in pnodes: node.setdefault('free',{})[p]=pnodes[n]
            jobs=client.get(pool=p,node=n,**kwargs)
            if jobs: node.setdefault('jobs',{})[p]=jobs
    #now we put nodes under other nodes
    s=nodes
    def _tree(s):
        for n in list(s.keys()):
            if n in s: #already moved?
                node=s[n]
                for dn in node.get('routing',[]):
                    if dn in s and dn != n: #we can move this node
                        s[n].setdefault('next',{})[dn]=s[dn]
                        del s[dn]
                if s[n].get('next'): _tree(s[n]['next']) #walk downstream
    _tree(s)
    #now we print the tree
    def _print(s,i=0):
        for n,node in sorted(s.items()):
            if 'nodes' in args:
                l='\t'*i + n+'\t'
                if node.get('online'): l+='online'
                else: l+='offline'
                l+='\t%s'%node.get('loadavg')
                print(l)
            pn=set(node.get('free',{}).keys())|set(node.get('jobs',{}).keys())
            for p in sorted(pn):
                if 'nodes' in args: l='\t'*i + '\t'
                else: l=''
                l+='pool %s@%s'%(p,n)
                jobs=node.get('jobs',{}).get(p,{})
                jc=len(jobs)
                l+='\t%s jobs'%jc
                free=node.get('free',{}).get(p)
                if type(free) is int: l+='\t%s slots free'%free
                if 'pools' in args and ('active' not in args or jc): print (l)
                l=''
                if 'nodes' in args: l+='\t'*i+'\t'
                if 'pools' in args: l+='\t'
                if 'jobs' in args:
                    for (jid,job) in sorted(jobs.items(),key=lambda j: (j[1].get('state')) ):
                        print(l+'%s\t%s\t%s'%(jid,job['state'],' '.join(job.get('args',[]))))
            if 'next' in node:
                _print(node['next'],i+1)
    _print(nodes,0)

# cmd=first non cfg argument
# args=remaining arguments
cfg={ 'address':'localhost' } 
try:
    cfg,args=cmdline_parser(sys.argv[1:])
    cmd,args=args[0],args[1:] #end of options
    if 'file' in cfg: cfg.update(read_cfg_files(cfg['file']))
    logging.basicConfig(level=cfg.get('log',logging.INFO))
    logging.debug('%s %s %s'%(cfg,cmd,args))
    client=Client(**cfg) #create client and connect
    jids,query=None,{}
    #if we will be refreshing, refresh now until state populated
    if cfg.get('refresh'):
        while not client.get_node_status(): time.sleep(1)
    if cmd == 'submit':
        #get pool, args and optional node selection
        pool=jobargs=node=None
        if args: 
            pool=args[0]
            if len(args)>1: jobargs=args[1:]
        if pool and '@' in pool: pool,node=pool.split('@',1)
        #if we are refreshing on the job, submit locally and let it dispatch
        if cfg.get('refresh'): jids=[client.submit_job(pool=pool,args=jobargs,node=node,**cfg)]
        #submit directly and return jid
        else: print(client.submit(pool=pool,args=jobargs,node=node,**cfg))
    else: #if not submit, parse as query args and job ids
        kwargs,args=cmdline_parser(args)
        if cmd == 'get':
            if cfg.get('refresh'):
                if args: jids=args
                else: jids=True #get all
            elif args:
                for arg in args: pretty_print({arg:client.query(arg)})
            else: pretty_print(client.query(**kwargs))
        elif cmd == 'kill': pretty_print(client.kill(args,**kwargs))
        elif cmd == 'ls': pretty_print(client.ls(**kwargs))
        elif cmd == 'nodes': 
            if cfg.get('refresh'): 
                while True:
                    pretty_print(client.get_node_status())
                    time.sleep(cfg.get('refresh'))
            else: pretty_print(client.status()['nodes'])
        elif cmd == 'pools': 
            if cfg.get('refresh'): 
                while True:
                    pretty_print(client.get_pool_status())
                    time.sleep(cfg.get('refresh'))
            else: pretty_print(client.status()['pools'])
        elif cmd == 'config': 
            if 'file' in kwargs: kwargs.update(read_cfg_files(kwargs['file']))
            if args:
                for node in args: 
                    print(client.submit(pool='__config',node=node,args=kwargs))
            else: pretty_print(client.request(dict(config=kwargs))) #peer config push
        elif cmd == 'show': show(args,**kwargs) #pretty print full cluster

        else: sys.exit(usage())
    
    #refreshing on jobs
    if jids:
        seq={} #sequence numbers for printing updates
        while True: 
            if jids is True: jobs=client.get(**kwargs)
            else: jobs=dict((jid,client.get_job(jid)) for jid in jids)
            if not any(jobs.values()): break #exit when no jobs left
            #print updates (when job seq != saved seq)
            updates=dict((jid,job) for (jid,job) in jobs.items() if job['seq'] != seq.get(jid))
            if updates: pretty_print(updates)
            seq=dict((jid,job['seq']) for (jid,job) in jobs.items())
            time.sleep(cfg.get('refresh'))
except Exception as e: print (e,file=sys.stderr)

#if we were polling state, stop gracefully
if cfg.get('refresh'): client.close()